{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import external and internal modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import math\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import *\n",
    "# importlib.reload(modules.utils)\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(361, 361, 2)\n"
     ]
    }
   ],
   "source": [
    "lat_csv = 'data/latitude_EASE.csv'\n",
    "lon_csv = 'data/longitude_EASE.csv'\n",
    "grid = generate_ease_grid(lat_csv, lon_csv)\n",
    "print(grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the EASE grid on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earth view\n",
    "fig = plt.figure(figsize=(8, 8), edgecolor='w')\n",
    "draw_map([], [], [], [], grid, fig, projection='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomed view\n",
    "fig = plt.figure(figsize=(8, 8), edgecolor='w')\n",
    "draw_map([], [], [], [], grid, fig, projection='stere', grid_res=4, width=5000000, height=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the sea ice dataset and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset('data/DRIFT_DATA_TRAIN.csv')\n",
    "#print(data.describe())\n",
    "'''\n",
    "data cleaning up\n",
    "'''\n",
    "# Remove any rows that have buoy velocity/mag =0 \n",
    "data = data.drop(data[data[\"u_buoy\"]*data[\"v_buoy\"] == 0].index)\n",
    "data = data.reset_index()\n",
    "\n",
    "# average the ice thickness from two measurements\n",
    "temp = [None]*data.shape[0]\n",
    "# iterate through all the rows and check if thickness is 0\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"h_piomas\"] == 0 :  \n",
    "        if row[\"h_cs2smos\"] > 0: \n",
    "            temp[index] = row[\"h_cs2smos\"]\n",
    "        elif row['sic_CDR'] < 0.001:\n",
    "            temp[index] = 0\n",
    "            \n",
    "    elif row[\"h_piomas\"] > 0:\n",
    "        if row[\"h_cs2smos\"] > 0:\n",
    "            temp[index] = (row[\"h_cs2smos\"] + row[\"h_piomas\"])/2\n",
    "        else: \n",
    "            temp[index] = row[\"h_piomas\"]\n",
    "            \n",
    "    else:\n",
    "         if row[\"h_cs2smos\"] > 0:\n",
    "            temp[index] = row[\"h_cs2smos\"]\n",
    "   \n",
    "        \n",
    "\n",
    "data[\"ice_thickness\"] = temp            \n",
    "\n",
    "# drop original thickness columns\n",
    "data = data.drop(['h_piomas', 'h_cs2smos'], axis = 1)\n",
    "\n",
    "# frop nan rows\n",
    "data = data.dropna()\n",
    "\n",
    "# convert x_EASE and y_EASE to lat and lon\n",
    "# convert velocity components to magnitude and angle\n",
    "lats = []\n",
    "lons = []\n",
    "buoy_vel_mags = []\n",
    "buoy_vel_dirs = []\n",
    "wind_vel_mags = []\n",
    "wind_vel_dirs = []\n",
    "for index, row in data.iterrows(): \n",
    "    # coordinate conversion\n",
    "    x = row['x_EASE']\n",
    "    y = row['y_EASE']\n",
    "    lat, lon = interpolate_coordinate(x, y, grid)\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "\n",
    "    # buoy velocity conversion\n",
    "    buoy_mag, buoy_dir = caonvert_vel_vector(row['u_buoy'], row['v_buoy'])\n",
    "    buoy_vel_mags.append(buoy_mag)\n",
    "    buoy_vel_dirs.append(buoy_dir)\n",
    "\n",
    "    # wind velocity conversion\n",
    "    wind_mag, wind_dir = caonvert_vel_vector(row['u_ERA5'], row['v_ERA5'])\n",
    "    wind_vel_mags.append(wind_mag)\n",
    "    wind_vel_dirs.append(wind_dir)\n",
    "\n",
    "# add the converted data to dataset\n",
    "data['buoy_lat'] = lats\n",
    "data['buoy_lon'] = lons\n",
    "data['buoy_vel_mag'] = buoy_vel_mags\n",
    "data['buoy_vel_dir'] = buoy_vel_dirs\n",
    "data['wind_vel_mag'] = wind_vel_mags\n",
    "data['wind_vel_dir'] = wind_vel_dirs\n",
    "\n",
    "# remove unwanted columns\n",
    "# data = data.drop(['u_buoy', 'v_buoy', 'u_ERA5', 'v_ERA5', 'x_EASE', 'y_EASE'], axis = 1)  \n",
    "\n",
    "# save the converted x_EASE and y_EASE to csv file\n",
    "data.to_csv('data/converted.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset from the saved csv file to prevent running the above cell\n",
    "data = pd.read_csv('data/converted.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the thickness\n",
    "data['ice_thick_norm'] =(data['ice_thickness'] - data['ice_thickness'].min()) / (data['ice_thickness'].max() - data['ice_thickness'].min())\n",
    "data['buoy_vel_norm'] =(data['buoy_vel_mag'] - data['buoy_vel_mag'].min()) / (data['buoy_vel_mag'].max() - data['buoy_vel_mag'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the dataset as a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = list(pd.unique(data['year']))\n",
    "\n",
    "if not os.path.exists('pictures/vis'):\n",
    "    os.makedirs('pictures/vis')\n",
    "\n",
    "for year in years_list:\n",
    "        \n",
    "    df = data[data['year'] == year]\n",
    "    buoys_list = pd.unique(df['id_buoy'])\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), edgecolor='w')\n",
    "    for b in buoys_list:\n",
    "        df_b = df[df['id_buoy'] == b]\n",
    "        lat, lon = df_b['buoy_lat'].to_list(), df_b['buoy_lon'].to_list()\n",
    "        thick = df_b['ice_thick_norm'].to_list()\n",
    "\n",
    "        visualize(lat, lon, grid, fig, projection='stere', \n",
    "                 show_grid=False, grid_res=4, width=5000000, height=5000000, \n",
    "                  show_text=True, year=year, thick=thick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# monthly avergae for all buoys through years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if not os.path.exists('pictures'):\n",
    "    os.makedirs('pictures')\n",
    "\n",
    "if not os.path.exists('pictures/all'):\n",
    "    os.makedirs('pictures/all')\n",
    "    \n",
    "buoys_list = list(pd.unique(data['id_buoy']))\n",
    "years_list = list(pd.unique(data['year']))\n",
    "\n",
    "# assign color to each buoy randomely\n",
    "colors = []\n",
    "r = random.random\n",
    "for i in range(0,len(buoys_list)):\n",
    "    rgb =  (r(),r(), 0)\n",
    "    colors.append(rgb)\n",
    "\n",
    "    \n",
    "for year in years_list:\n",
    "    # create the folders\n",
    "    if not os.path.exists('pictures/{}'.format(year)):\n",
    "        os.makedirs('pictures/{}'.format(year))\n",
    "\n",
    "    df = data[data['year'] == year]\n",
    "    month_list = list(pd.unique(df['month']))\n",
    "\n",
    "    lat_avg = df.groupby(['month','id_buoy']).agg({'buoy_lat': ['mean']})     #agg({'buoy_lat': ['mean', 'min', 'max','std']})\n",
    "    lon_avg = df.groupby(['month','id_buoy']).agg({'buoy_lon': ['mean']}) \n",
    "    thick_avg = df.groupby(['month','id_buoy']).agg({'ice_thick_norm': ['mean']}) \n",
    "    vel_avg = df.groupby(['month','id_buoy']).agg({'buoy_vel_norm': ['mean']}) \n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), edgecolor='w')\n",
    "    for m in month_list:\n",
    "        lat = lat_avg.loc[m, ('buoy_lat', 'mean')].values\n",
    "        lon = lon_avg.loc[m, ('buoy_lon', 'mean')].values\n",
    "        thick = thick_avg.loc[m, ('ice_thick_norm', 'mean')].values\n",
    "        vel = vel_avg.loc[m, ('buoy_vel_norm', 'mean')].values\n",
    "        current_buoys = list((lat_avg.loc[m, ('buoy_lat', 'mean')]).index)\n",
    "        color = []\n",
    "        for b in current_buoys:\n",
    "            idx = buoys_list.index(b)\n",
    "            color.append(colors[idx])\n",
    "\n",
    "        draw_map(lat, lon, thick, color, grid, fig, projection='stere', \n",
    "                 show_grid=False, grid_res=4, width=4000000, height=4000000,\n",
    "                 year=year, month=m, doy=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# motion of one buoy through years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if not os.path.exists('pictures'):\n",
    "    os.makedirs('pictures')\n",
    "\n",
    "if not os.path.exists('pictures/all'):\n",
    "    os.makedirs('pictures/all')\n",
    "\n",
    "    # find the most repeated buoys and plot their motion\n",
    "dfl = data.groupby('id_buoy')['year'].nunique()\n",
    "dfl = dfl.sort_values(ascending=False)\n",
    "print(dfl)\n",
    "\n",
    "buoy = 2416\n",
    "df = data[data['id_buoy'] == buoy]\n",
    "years_list = pd.unique(df['year'])\n",
    "\n",
    "    \n",
    "for year in years_list:\n",
    "    if year < 2002:\n",
    "        continue\n",
    "    # create the folders\n",
    "    if not os.path.exists('pictures/{}'.format(year)):\n",
    "        os.makedirs('pictures/{}'.format(year))\n",
    "\n",
    "    dfn = df[df['year'] == year]\n",
    "    month_list = list(pd.unique(dfn['month']))\n",
    "\n",
    "    lat = list(dfn['buoy_lat'].values)\n",
    "    lon = list(dfn['buoy_lon'].values)\n",
    "    thickness = list(dfn['ice_thick_norm'].values)\n",
    "    doy = list(dfn['doy'].values)\n",
    "\n",
    "    for i in range(len(lat)):\n",
    "        fig = plt.figure(figsize=(8, 8), edgecolor='w')\n",
    "        draw_map([lat[i]], [lon[i]], thickness[i] , thickness[i], grid, fig, projection='stere', \n",
    "                 show_grid=False, grid_res=4, width=4000000, height=4000000,\n",
    "                 year=year, month=1, doy=doy[i])        \n",
    "    "
   ]
  },
  {
   "source": [
    "# read the provided test data and clean it up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       year  month  day  doy      x_EASE      y_EASE    u_ERA5    v_ERA5  \\\n0      1979      2   18   49  197.656311  204.507797  5.998414  3.617303   \n1      1979      2   19   50  197.769897  204.840912 -1.414826 -0.201038   \n2      1979      2   19   50  147.548553  157.382889 -4.140861  3.038851   \n3      1979      2   20   51  146.934814  120.546783  2.998362  4.055094   \n4      1979      2   21   52  197.534439  204.845886 -8.538108  4.243983   \n...     ...    ...  ...  ...         ...         ...       ...       ...   \n84865  2019     12   30  364   51.783913  255.659637 -3.079250  8.509069   \n84866  2019     12   30  364  195.420746  101.970360 -7.462417 -2.639882   \n84867  2019     12   30  364  147.647980  104.794327 -1.493360 -3.978977   \n84868  2019     12   30  364  200.005966  174.816803 -1.934895 -1.281953   \n84869  2019     12   30  364  191.944336  173.387054 -2.627429 -6.525005   \n\n        sic_CDR         d2c  ice_thickness   buoy_lat    buoy_lon  \\\n0      0.987723  375.766965       2.535649  83.278894   55.245082   \n1      0.964051  370.636136       2.539519  83.263783   55.610016   \n2      1.000000  381.590523       3.746467  81.023992 -145.578490   \n3      1.000000  413.672796       2.496566  74.509120 -119.765602   \n4      0.978987  376.255493       2.530706  83.295108   55.615465   \n...         ...         ...            ...        ...         ...   \n84865  0.003184   25.612993       0.019423  56.018602  149.608252   \n84866  0.995414  177.841985       1.086896  71.777914  -79.118458   \n84867  0.986766   21.720861       1.228123  71.296458 -113.692218   \n84868  1.000000  527.681133       1.430554  85.290268  -14.524094   \n84869  1.000000  731.985737       1.534502  86.878560  -30.976877   \n\n       wind_vel_mag  wind_vel_dir  \n0          7.004702      0.542654  \n1          1.429038      3.282756  \n2          5.136277      2.508495  \n3          5.043210      0.934110  \n4          9.534709      2.680297  \n...             ...           ...  \n84865      9.049090      1.918014  \n84866      7.915595      3.481625  \n84867      4.249986      4.353359  \n84868      2.321039      3.726751  \n84869      7.034136      4.329597  \n\n[84870 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>doy</th>\n      <th>x_EASE</th>\n      <th>y_EASE</th>\n      <th>u_ERA5</th>\n      <th>v_ERA5</th>\n      <th>sic_CDR</th>\n      <th>d2c</th>\n      <th>ice_thickness</th>\n      <th>buoy_lat</th>\n      <th>buoy_lon</th>\n      <th>wind_vel_mag</th>\n      <th>wind_vel_dir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979</td>\n      <td>2</td>\n      <td>18</td>\n      <td>49</td>\n      <td>197.656311</td>\n      <td>204.507797</td>\n      <td>5.998414</td>\n      <td>3.617303</td>\n      <td>0.987723</td>\n      <td>375.766965</td>\n      <td>2.535649</td>\n      <td>83.278894</td>\n      <td>55.245082</td>\n      <td>7.004702</td>\n      <td>0.542654</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979</td>\n      <td>2</td>\n      <td>19</td>\n      <td>50</td>\n      <td>197.769897</td>\n      <td>204.840912</td>\n      <td>-1.414826</td>\n      <td>-0.201038</td>\n      <td>0.964051</td>\n      <td>370.636136</td>\n      <td>2.539519</td>\n      <td>83.263783</td>\n      <td>55.610016</td>\n      <td>1.429038</td>\n      <td>3.282756</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979</td>\n      <td>2</td>\n      <td>19</td>\n      <td>50</td>\n      <td>147.548553</td>\n      <td>157.382889</td>\n      <td>-4.140861</td>\n      <td>3.038851</td>\n      <td>1.000000</td>\n      <td>381.590523</td>\n      <td>3.746467</td>\n      <td>81.023992</td>\n      <td>-145.578490</td>\n      <td>5.136277</td>\n      <td>2.508495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979</td>\n      <td>2</td>\n      <td>20</td>\n      <td>51</td>\n      <td>146.934814</td>\n      <td>120.546783</td>\n      <td>2.998362</td>\n      <td>4.055094</td>\n      <td>1.000000</td>\n      <td>413.672796</td>\n      <td>2.496566</td>\n      <td>74.509120</td>\n      <td>-119.765602</td>\n      <td>5.043210</td>\n      <td>0.934110</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979</td>\n      <td>2</td>\n      <td>21</td>\n      <td>52</td>\n      <td>197.534439</td>\n      <td>204.845886</td>\n      <td>-8.538108</td>\n      <td>4.243983</td>\n      <td>0.978987</td>\n      <td>376.255493</td>\n      <td>2.530706</td>\n      <td>83.295108</td>\n      <td>55.615465</td>\n      <td>9.534709</td>\n      <td>2.680297</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>84865</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>364</td>\n      <td>51.783913</td>\n      <td>255.659637</td>\n      <td>-3.079250</td>\n      <td>8.509069</td>\n      <td>0.003184</td>\n      <td>25.612993</td>\n      <td>0.019423</td>\n      <td>56.018602</td>\n      <td>149.608252</td>\n      <td>9.049090</td>\n      <td>1.918014</td>\n    </tr>\n    <tr>\n      <th>84866</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>364</td>\n      <td>195.420746</td>\n      <td>101.970360</td>\n      <td>-7.462417</td>\n      <td>-2.639882</td>\n      <td>0.995414</td>\n      <td>177.841985</td>\n      <td>1.086896</td>\n      <td>71.777914</td>\n      <td>-79.118458</td>\n      <td>7.915595</td>\n      <td>3.481625</td>\n    </tr>\n    <tr>\n      <th>84867</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>364</td>\n      <td>147.647980</td>\n      <td>104.794327</td>\n      <td>-1.493360</td>\n      <td>-3.978977</td>\n      <td>0.986766</td>\n      <td>21.720861</td>\n      <td>1.228123</td>\n      <td>71.296458</td>\n      <td>-113.692218</td>\n      <td>4.249986</td>\n      <td>4.353359</td>\n    </tr>\n    <tr>\n      <th>84868</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>364</td>\n      <td>200.005966</td>\n      <td>174.816803</td>\n      <td>-1.934895</td>\n      <td>-1.281953</td>\n      <td>1.000000</td>\n      <td>527.681133</td>\n      <td>1.430554</td>\n      <td>85.290268</td>\n      <td>-14.524094</td>\n      <td>2.321039</td>\n      <td>3.726751</td>\n    </tr>\n    <tr>\n      <th>84869</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>364</td>\n      <td>191.944336</td>\n      <td>173.387054</td>\n      <td>-2.627429</td>\n      <td>-6.525005</td>\n      <td>1.000000</td>\n      <td>731.985737</td>\n      <td>1.534502</td>\n      <td>86.878560</td>\n      <td>-30.976877</td>\n      <td>7.034136</td>\n      <td>4.329597</td>\n    </tr>\n  </tbody>\n</table>\n<p>84870 rows Ã— 15 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "data = read_dataset('data/DRIFT_DATA_TEST.csv')\n",
    "#print(data.describe())\n",
    "'''\n",
    "data cleaning up\n",
    "'''\n",
    "# data['h_cs2smos'].isna().sum()\n",
    "data = data.drop(['u_buoy', 'v_buoy', 'id_buoy'], axis=1)\n",
    "# average the ice thickness from two measurements\n",
    "temp = [None]*data.shape[0]\n",
    "# iterate through all the rows and check if thickness is 0\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"h_piomas\"] == 0 :  \n",
    "        if row[\"h_cs2smos\"] > 0: \n",
    "            temp[index] = row[\"h_cs2smos\"]\n",
    "        else:\n",
    "            temp[index] = 0\n",
    "            \n",
    "    elif row[\"h_piomas\"] > 0:\n",
    "        if row[\"h_cs2smos\"] > 0:\n",
    "            temp[index] = (row[\"h_cs2smos\"] + row[\"h_piomas\"])/2\n",
    "        else: \n",
    "            temp[index] = row[\"h_piomas\"]\n",
    "            \n",
    "    else:\n",
    "         if row[\"h_cs2smos\"] > 0:\n",
    "            temp[index] = row[\"h_cs2smos\"]\n",
    "   \n",
    "data[\"ice_thickness\"] = temp            \n",
    "\n",
    "# drop original thickness columns\n",
    "data = data.drop(['h_piomas', 'h_cs2smos'], axis = 1)\n",
    "\n",
    "# frop nan rows\n",
    "data = data.dropna()\n",
    "\n",
    "# convert x_EASE and y_EASE to lat and lon\n",
    "# convert velocity components to magnitude and angle\n",
    "lats = []\n",
    "lons = []\n",
    "buoy_vel_mags = []\n",
    "buoy_vel_dirs = []\n",
    "wind_vel_mags = []\n",
    "wind_vel_dirs = []\n",
    "for index, row in data.iterrows(): \n",
    "    # coordinate conversion\n",
    "    x = row['x_EASE']\n",
    "    y = row['y_EASE']\n",
    "    lat, lon = interpolate_coordinate(x, y, grid)\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "\n",
    "    # wind velocity conversion\n",
    "    wind_mag, wind_dir = caonvert_vel_vector(row['u_ERA5'], row['v_ERA5'])\n",
    "    wind_vel_mags.append(wind_mag)\n",
    "    wind_vel_dirs.append(wind_dir)\n",
    "\n",
    "# add the converted data to dataset\n",
    "data['buoy_lat'] = lats\n",
    "data['buoy_lon'] = lons\n",
    "data['wind_vel_mag'] = wind_vel_mags\n",
    "data['wind_vel_dir'] = wind_vel_dirs\n",
    "\n",
    "display(data)\n",
    "\n",
    "# save the converted x_EASE and y_EASE to csv file\n",
    "data.to_csv('data/converted_test.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.hack')",
   "language": "python",
   "name": "python38564bithack53bc31e56d28430eb90a34f623204bce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}